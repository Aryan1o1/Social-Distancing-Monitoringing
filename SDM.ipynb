{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yBYlgfqlYlG"
      },
      "source": [
        "# **Setting up the variable values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOnb8sDa0E0f"
      },
      "outputs": [],
      "source": [
        "import struct\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mXrEGHK0F7V"
      },
      "outputs": [],
      "source": [
        "def _conv_block(inp, convs, skip=True):\n",
        "    x = inp\n",
        "    count = 0\n",
        "    for conv in convs:\n",
        "        if count == (len(convs) - 2) and skip:\n",
        "            skip_conn ection = x\n",
        "        count += 1\n",
        "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) #padding as darknet prefer left and top\n",
        "        x = Conv2D(conv['filter'],\n",
        "                   conv['kernel'],\n",
        "                   strides=conv['stride'],\n",
        "                   padding='valid' if conv['stride'] > 1 else 'same', #  padding as darknet prefer left and top\n",
        "                   name='conv_' + str(conv['layer_idx']),\n",
        "                   use_bias=False if conv['bnorm'] else True)(x)\n",
        "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "    return add([skip_connection, x]) if skip else x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sb5MAxqt0Gjc"
      },
      "outputs": [],
      "source": [
        "def make_yolov3_model():\n",
        "    input_image = Input(shape=(None, None, 3))\n",
        "    # Layer  0 => 4\n",
        "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "    # Layer  5 => 8\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "    # Layer  9 => 11\n",
        "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "    # Layer 12 => 15\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "    # Layer 16 => 36\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "    skip_36 = x\n",
        "    # Layer 37 => 40\n",
        "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "    # Layer 41 => 61\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "    skip_61 = x\n",
        "    # Layer 62 => 65\n",
        "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "    # Layer 66 => 74\n",
        "    for i in range(3):\n",
        "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "    # Layer 75 => 79\n",
        "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "    # Layer 80 => 82\n",
        "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
        "    # Layer 83 => 86\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_61])\n",
        "    # Layer 87 => 91\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "    # Layer 92 => 94\n",
        "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
        "    # Layer 95 => 98\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_36])\n",
        "    # Layer 99 => 106\n",
        "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
        "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eykFzfJA0Go5"
      },
      "outputs": [],
      "source": [
        "class WeightReader:\n",
        "    def __init__(self, weight_file):\n",
        "        with open(weight_file, 'rb') as w_f:\n",
        "            major,\t= struct.unpack('i', w_f.read(4))\n",
        "            minor,\t= struct.unpack('i', w_f.read(4))\n",
        "            revision, = struct.unpack('i', w_f.read(4))\n",
        "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
        "                w_f.read(8)\n",
        "            else:\n",
        "                w_f.read(4)\n",
        "            transpose = (major > 1000) or (minor > 1000)\n",
        "            binary = w_f.read()\n",
        "        self.offset = 0\n",
        "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
        "\n",
        "    def read_bytes(self, size):\n",
        "        self.offset = self.offset + size\n",
        "        return self.all_weights[self.offset-size:self.offset]\n",
        "\n",
        "    def load_weights(self, model):\n",
        "        for i in range(106):\n",
        "            try:\n",
        "                conv_layer = model.get_layer('conv_' + str(i))\n",
        "                print(\"loading weights of convolution #\" + str(i))\n",
        "                if i not in [81, 93, 105]:\n",
        "                    norm_layer = model.get_layer('bnorm_' + str(i))\n",
        "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
        "                    beta  = self.read_bytes(size) # bias\n",
        "                    gamma = self.read_bytes(size) # scale\n",
        "                    mean  = self.read_bytes(size) # mean\n",
        "                    var   = self.read_bytes(size) # variance\n",
        "                    weights = norm_layer.set_weights([gamma, beta, mean, var])\n",
        "                if len(conv_layer.get_weights()) > 1:\n",
        "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel, bias])\n",
        "                else:\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel])\n",
        "            except ValueError:\n",
        "                print(\"no convolution #\" + str(i))\n",
        "\n",
        "    def reset(self):\n",
        "        self.offset = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39sIjr3C0Gqu"
      },
      "outputs": [],
      "source": [
        "# define the model\n",
        "model = make_yolov3_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efUN-JQW0GtE"
      },
      "outputs": [],
      "source": [
        "weight_reader = WeightReader('yolov3.weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQT-F3tu0Gwd"
      },
      "outputs": [],
      "source": [
        "weight_reader.load_weights(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpEuGy_w0G3e"
      },
      "outputs": [],
      "source": [
        "model.save('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHuIGXvY0G5j"
      },
      "outputs": [],
      "source": [
        "from numpy import expand_dims\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "#from make_ import model\n",
        "\n",
        "# load model\n",
        "model = load_model('model.h5')\n",
        "\n",
        "# input shape for the model\n",
        "input_w, input_h = 416, 416\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcTE0EOf0gWP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "\n",
        "        return self.label\n",
        "\n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "\n",
        "        return self.score\n",
        "\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmpyrZ1q0gfE"
      },
      "outputs": [],
      "source": [
        "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
        "    grid_h, grid_w = netout.shape[:2] \n",
        "    nb_box = \n",
        "    netout = netout.reshape((grid_h, grid_w, nb_box, -1)) #13*13*3 ,-1\n",
        "    nb_class = netout.shape[-1] - 5\n",
        "    boxes = []\n",
        "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        "\n",
        "    for i in range(grid_h*grid_w):\n",
        "        row = i / grid_w\n",
        "        col = i % grid_w\n",
        "        for b in range(nb_box):\n",
        "            objectness = netout[int(row)][int(col)][b][4]\n",
        "            if(objectness.all() <= obj_thresh): continue\n",
        "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "            x = (col + x) / grid_w \n",
        "            y = (row + y) / grid_h\n",
        "            w = anchors[2 * b + 0] * np.exp(w) / net_w \n",
        "            h = anchors[2 * b + 1] * np.exp(h) / net_h \n",
        "            \n",
        "            classes = netout[int(row)][col][b][5:]\n",
        "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "            boxes.append(box)\n",
        "    return boxes\n",
        "\n",
        "\n",
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "    new_w, new_h = net_w, net_h\n",
        "    for i in range(len(boxes)):\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSB8tGc70gha"
      },
      "outputs": [],
      "source": [
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3\n",
        "\n",
        "#intersection over union        \n",
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "    intersect = intersect_w * intersect_h\n",
        "    \n",
        "    \n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin  \n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "    \n",
        "    # A + B - I(A,B)\n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "    return float(intersect) / union\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpWIPcAQ0gjg"
      },
      "outputs": [],
      "source": [
        "def do_nms(boxes, nms_thresh):    \n",
        "    if len(boxes) > 0:\n",
        "        nb_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "    for c in range(nb_class):\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                index_j = sorted_indices[j]\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLcdTUl0glD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_image_pixels(filename, shape):\n",
        "    \n",
        "    image = load_img(filename) \n",
        "    width, height = image.size\n",
        "    \n",
        "    image = load_img(filename, target_size=shape) \n",
        "    image = img_to_array(image)\n",
        "    \n",
        "    image = image.astype('float32')\n",
        "    image /= 255.0  \n",
        "    image = expand_dims(image, 0)\n",
        "    return image, width, height\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bppIQYl0gnI"
      },
      "outputs": [],
      "source": [
        "from numpy import expand_dims\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "photo_filename = '/content/images.jpg'\n",
        "input_w, input_h = 416, 416\n",
        "\n",
        "image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
        "#print(image, image_w, image_h )\n",
        "print(image.shape)\n",
        "# make prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdOTFBe-0xVF"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = load_model('model.h5')\n",
        "yhat = model.predict(image)\n",
        "\n",
        "\n",
        "\n",
        "print([a.shape for a in yhat])\n",
        "# 3 anchor boxes and 80 classes\n",
        "# 13*13*3*85 (80+5)  13*13*255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we0fVuaS0xeD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_boxes(boxes, labels, thresh):\n",
        "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
        "    \n",
        "    for box in boxes:\n",
        "       \n",
        "        for i in range(len(labels)):\n",
        "            \n",
        "            if box.classes[i] > thresh:\n",
        "                v_boxes.append(box)\n",
        "                v_labels.append(labels[i])\n",
        "                v_scores.append(box.classes[i]*100)\n",
        "\n",
        "    return v_boxes, v_labels, v_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS1z4hW40xiP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "    \n",
        "    data = pyplot.imread(filename)\n",
        "    \n",
        "    pyplot.imshow(data)\n",
        "    \n",
        "    ax = pyplot.gca()\n",
        "    \n",
        "    for i in range(len(v_boxes)):\n",
        "        \n",
        "        \n",
        "        box = v_boxes[i]\n",
        "        \n",
        "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "        \n",
        "        width, height = x2 - x1, y2 - y1\n",
        "       \n",
        "        rect = Rectangle((x1, y1), width, height, fill=False, color='white') \n",
        "        \n",
        "        ax.add_patch(rect)\n",
        "        \n",
        "        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
        "        pyplot.text(x1, y1, label, color='white')\n",
        "    \n",
        "    pyplot.show()\n",
        "draw_boxes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KevY4mlL05ZW"
      },
      "outputs": [],
      "source": [
        "\n",
        "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]  \n",
        "\n",
        "\n",
        "\n",
        "class_threshold = 0.6\n",
        "boxes = list()\n",
        "for i in range(len(yhat)):\n",
        "    \n",
        "    boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
        "    \n",
        "\n",
        "correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
        "\n",
        "\n",
        "do_nms(boxes, 0.5)  \n",
        "\n",
        "\n",
        "labels = [\"person\"]\n",
        "\n",
        "# get the details of the detected objects\n",
        "v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
        "\n",
        "\n",
        "for i in range(len(v_boxes)):\n",
        "        print(v_labels[i], v_scores[i])\n",
        "draw_boxes(photo_filename, v_boxes, v_labels, v_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPXOB1zJhPKQ"
      },
      "outputs": [],
      "source": [
        "# initialize minimum probability to filter weak detections \n",
        "MIN_CONF = 0.3\n",
        "# initialize threshold when applying non-maxima suppression\n",
        "NMS_THRESH = 0.3\n",
        "# define min_pixel distance\n",
        "MIN_DISTANCE = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mefw6DVRlyuQ"
      },
      "source": [
        "# **Detection Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQgUUsQRhqoA"
      },
      "outputs": [],
      "source": [
        "# import the packages\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "labelsPath = os.path.sep.join([\"/content/coco.names\"])\n",
        "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
        "\n",
        "def detection(frame, net, ln, personIdx=LABELS.index(\"person\")):\n",
        "\t\n",
        "\tprint(frame)\n",
        "\t(H, W) = frame.shape[:2]\n",
        "\tresults = []\n",
        "\n",
        "\t# make a blob and then perform a forward pass of the YOLO object give bounding boxes and prob\n",
        "\n",
        "\tblob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),\n",
        "\t\tswapRB=True, crop=False)\n",
        "\tnet.setInput(blob)\n",
        "\tlayerOutputs = net.forward(ln)\n",
        "\n",
        "\t# initialize our lists of detected bounding boxes, centroids, and\n",
        "\t# confidences, respectively\n",
        "\tboxes = []\n",
        "\tcentroids = []\n",
        "\tconfidences = []\n",
        "\n",
        "\t# loop :layer outputs\n",
        "\tfor output in layerOutputs:\n",
        "\t\t# loop : each detections\n",
        "\t\tfor detection in output:\n",
        "\t\t\tscores = detection[5:]\n",
        "\t\t\tclassID = np.argmax(scores)\n",
        "\t\t\tconfidence = scores[classID]\n",
        "\n",
        "\t\t\tif classID == personIdx and confidence > MIN_CONF:\n",
        "\t\t\t\t# scale the bounding box coordinates \n",
        "\t\t\t\tbox = detection[0:4] * np.array([W, H, W, H])\n",
        "\t\t\t\t(centerX, centerY, width, height) = box.astype(\"int\")\n",
        "\n",
        "\t\t\t\t# find top and left corner \n",
        "\t\t\t\tx = int(centerX - (width / 2))\n",
        "\t\t\t\ty = int(centerY - (height / 2))\n",
        "\n",
        "\t\t\t\t# update list \n",
        "\t\t\t\tboxes.append([x, y, int(width), int(height)])\n",
        "\t\t\t\tcentroids.append((centerX, centerY))\n",
        "\t\t\t\tconfidences.append(float(confidence))\n",
        "\n",
        "\t# NMS\n",
        "\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, MIN_CONF, NMS_THRESH)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\tif len(idxs) > 0:\n",
        "\t\tfor i in idxs.flatten():\n",
        "\t\t\n",
        "\t\t\t(x, y) = (boxes[i][0], boxes[i][1])\n",
        "\t\t\t(w, h) = (boxes[i][2], boxes[i][3])\n",
        "\t\t\tr = (confidences[i], (x, y, x + w, y + h), centroids[i])\n",
        "\t\t\tresults.append(r)\n",
        "\n",
        "\n",
        "\tprint(results)\n",
        "\treturn results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHLWA1WTmBlE"
      },
      "source": [
        "# **capture frame and detect**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DMWw6mhGHj7S",
        "outputId": "8dbebb2c-d83a-4bad-8dc8-f252cb0290c4"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from scipy.spatial import distance as dist\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-i\", \"--input\", type=str, default=\"\",\n",
        "\thelp=\"path to (optional) input video file\")\n",
        "ap.add_argument(\"-o\", \"--output\", type=str, default=\"\",\n",
        "\thelp=\"path to (optional) output video file\")\n",
        "ap.add_argument(\"-d\", \"--display\", type=int, default=1,\n",
        "\thelp=\"whether or not output frame should be displayed\")\n",
        "args = vars(ap.parse_args([\"--input\",\"/content/input.mp4\",\"--output\",\"my_output.avi\",\"--display\",\"1\"]))\n",
        "\n",
        "\n",
        "labelsPath = os.path.sep.join([\"/content/coco.names\"])\n",
        "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
        "\n",
        "\n",
        "weightsPath = os.path.sep.join([\"/content/yolov3.weights\"])\n",
        "configPath = os.path.sep.join([\"/content/yolov3.cfg\"])\n",
        "\n",
        "# load yolo object detector \n",
        "print(\"[INFO] loading YOLO from disk...\")\n",
        "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
        "\n",
        "\n",
        "ln = net.getLayerNames()\n",
        "ln = [ln[i- 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "print(\"[INFO] accessing video stream...\")\n",
        "vs = cv2.VideoCapture(args[\"input\"] if args[\"input\"] else 0)\n",
        "writer = None\n",
        "\n",
        "# loop:the frames \n",
        "while True:\n",
        "\t# read next frame\n",
        "\t(grabbed, frame) = vs.read()\n",
        "\n",
        "\n",
        "\tif not grabbed:\n",
        "\t\tbreak\n",
        "\tframe = imutils.resize(frame, width=700)\n",
        " \n",
        "\n",
        "\n",
        "\tresults = detection(frame, net, ln)\n",
        "\n",
        "\t\n",
        "\tviolate = set()\n",
        "\n",
        "\t\n",
        "\tif len(results) >= 2:\n",
        "\t\t# find all centroid and find euclidean distance\n",
        "\t\tcentroids = np.array([r[2] for r in results])\n",
        "\t\tD = dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
        "\n",
        "\t\t\n",
        "\t\tfor i in range(0, D.shape[0]):\n",
        "\t\t\tfor j in range(i + 1, D.shape[1]):\n",
        "\t\t\t\t# check the condition\n",
        "\t\t\t\tif D[i, j] < MIN_DISTANCE:\n",
        "\t\t\t\t\t# increment the counter in violate set\n",
        "\t\t\t\t\tviolate.add(i)\n",
        "\t\t\t\t\tviolate.add(j)\n",
        "\n",
        "\t# loop:result\n",
        "\tfor (i, (prob, bbox, centroid)) in enumerate(results):\n",
        "\t\t\n",
        "\t\t(startX, startY, endX, endY) = bbox\n",
        "\t\t(cX, cY) = centroid\n",
        "\t\tcolor = (0, 255, 0)\n",
        "\n",
        "\t\n",
        "\t\tif i in violate:\n",
        "\t\t\tcolor = (0, 0, 255)\n",
        "\n",
        "\t\t# draw bounding box\n",
        "\t\tcv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
        "\t\tcv2.circle(frame, (cX, cY), 5, color, 1)\n",
        "\n",
        "\t# show number of violations on the output\n",
        "\t\n",
        "\ttext = \"Social Distancing Violations: {}\".format(len(violate))\n",
        "\tcv2.putText(frame, text, (10, frame.shape[0] - 25),\n",
        "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 3)\n",
        "\n",
        "\t\n",
        "\tif args[\"display\"] > 0:\n",
        "\t\t\n",
        "\t\tcv2_imshow(frame)\n",
        "\t\tkey = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "\t\t\n",
        "\t\tif key == ord(\"q\"):\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\n",
        "\tif args[\"output\"] != \"\" and writer is None:\n",
        "\t\t\n",
        "\t\tfourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "\t\twriter = cv2.VideoWriter(args[\"output\"], fourcc, 25,\n",
        "\t\t\t(frame.shape[1], frame.shape[0]), True)\n",
        "\n",
        "\n",
        "\tif writer is not None:\n",
        "\t\twriter.write(frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewlSjQYWnZ0K"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}